---
title: "Variable Importance for Oblique Learning Ensembles of Trees (VIOLET)"
description: |
  Preliminary results for BERD pilot application
author:
  - name: Byron C. Jaeger
affiliation: Wake Forest School of Medicine
date: "`r Sys.Date()`"
output:
  distill::distill_article:
  toc: true
toc_depth: 2
code_folding: true
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = FALSE)

source(here::here("packages.R"))

source("R/sim_surv.R")

rspec <- round_spec() |> 
  round_using_magnitude(digits = c(3, 2, 1, 1),
                        breaks = c(1, 10, 100, Inf))

names(rspec) <- paste('table.glue', names(rspec), sep = '.')

options(rspec)

tar_load(names = benchmark_vi_smry)

```



## Introduction

This document shows the full preliminary results that I have included in my application for the Biostatistics, Epidemiology, and Research Design (BERD) Program's Methods Pilot Award. The data simulation process is described in full detail, followed by an outline of the proposed simulation study. Last, results are tabulated for each simulation scenario described, and also in aggregate form. The final aggregate table is presented in the BERD application.  

## Data Simulation 

A simulated data set with five types of predictor variables was generated in each run for the current simulation study. The size of each predictor set was fixed at 25 for our analysis. 

- $z$ (irrelevant) variables $z_1$, $\dots$, $z_{25}$ had no relationship with the outcome.

- $x$ (linear effect) variables $x_1$, $\dots$, $x_{25}$ had a linear relationship with the outcome.

- $w$ (non-linear effect) variables $w_1$, $\dots$, $w_{25}$ had a non-linear relationship with the outcome. The non-linear relationship followed a sinusoidal curve with varying period length.

- $g$ (conditional linear) variables $g_1$, $\dots$, $g_{25}$ had a conditional linear relationship with the outcome. In other words, for each $i \in \{1, \ldots, 25\}$,  $g_i$ had no relationship to the outcome, but $g_i * x_i$ was linearly related to the outcome.

- $v$ (combination linear) variables $v_1$, $\dots$, $v_{25}$ had a combination linear relationship with the outcome. In other words, $v_1, v_2, v_3$ each had no effect on the outcome individually, but the latent variable $v_1*c_1* + v_2*c_2 + v_3 * c_3$ was linearly related to the outcome. Coefficients $c_i$ were generated at random uniformly from -1 to -0.5 and 0.5 to 1.

__Mean and standard deviation__ The multivariate normal distribution that generated values for the predictor matrix had a mean of zero and standard deviation of 1 for each variable. 

__Correlation__: The correlation among $z$ variables was allowed to be non-zero as was the correlation among $x$ variables and the correlation between $x$ and $z$ variables. For all non-zero correlations, a value was selected at random uniformly between a lower and upper boundary. We simulated five scenarios by varying the boundaries of correlation:

1. lower bound: 0; upper bound: 0
1. lower bound: -0.1; upper bound: 0.1
2. lower bound: -0.2; upper bound: 0.2
1. lower bound: -0.3; upper bound: 0.3
3. lower bound: -0.4; upper bound: 0.4

The correlations were generated symmetrically and were adjusted if needed to create the nearest positive definite covariance matrix using `Matrix::nearPD()`.

__Effect sizes__: A total effect of 3 was distributed evenly across each predictor group. For example, with 25 $x$ predictors, the increase in log-hazard associated with a 1 unit increased in each $x$ variable was $3 / 25 = 0.12$. 

__Outcomes__: A censored outcome variable was generated with the `simsurv::simsurv()` using a predictor matrix that included all relevant predictors. After the outcome was generated the interactions, non-linear transformations, and linear combinations of relevant predictors were dropped from the data. 

### Demo and validation of simulated data

Some tests of the simulated data are presented below. If you have no skepticism regarding the simulated data, you can safely skip this sub-section. For simplicity, we set the number of predictors to 3 for each predictor group.

__Data generation__: There are no tests for this step, just a glimpse of the simulated set of data.

```{r}

set.seed(32987)

ss_demo <-
  sim_surv(
    n_obs = 5000,
    n_z = 3,
    n_x = 3,
    n_g = 3,
    n_w = 3,
    n_v = 3,
    # omit categorical variables; these are tested separately
    n_c = 0 
  )

glimpse(ss_demo$data)

```

__Column means__: This test verifies that the mean of each predictor is close to zero, and that roughly 45% of outcomes were censored.

```{r}

data_sim <- ss_demo$data

data_sim$true_v <- 
  with(
    data_sim,
      v1 * ss_demo$coefs_lc[[1]][1] + 
      v2 * ss_demo$coefs_lc[[1]][2] + 
      v3 * ss_demo$coefs_lc[[1]][3] 
  )

data_means <- data_sim |> 
  select(where(is.numeric)) |> 
  apply(2, mean) |> 
  round(3) |> 
  enframe()

# we can see that the mean of each predictor is close to zero, and that roughly 40% of outcomes were censored.
data_means

```

__Effects detected__: This test verifies that, when the oracle model is used, an effect is only detected for variables that have a relationship to the outcome.

```{r}

dd <- datadist(data_sim)
options(datadist = dd)

mdl <- cph(
  Surv(time, status) ~ 
    # z variables; no effect should be detected
    z1 + z2 + z3 +
    # x variables; effect should be detected
    # g variables; no effect should be detected
    # interaction between x and g; effect should be detected
    x1*g1 + x2*g2 + x3*g3 + 
    # w variables; effect should be detected and should be nonlinear
    rcs(w1) + rcs(w2) + rcs(w3) + 
    # v variables; no effect should be detected for individual
    # variables v1, v2, and v3, but the linear combination of
    # these variables should have a detectable effect.
    # note: v1 is not included due to co-linearity 
    v2 + v3 + true_v,
  data = data_sim
)

# All expectations outlined above are met!
anova(mdl)

```

__Effect size estimation for linear effects__: This test verifies that, when the oracle model is used, the estimated effect sizes for variables with linear effects are consistent with the effect sizes used to simulate the data.

```{r}

effects_expected <- c("x1" = 1, 
                      "x2" = 1, 
                      "x3" = 1,
                      "g1" = 0,
                      "g2" = 0,
                      "g3" = 0,
                      "x1 * g1" = 1,       
                      "x2 * g2" = 1,       
                      "x3 * g3" = 1, 
                      "v2" = 0,
                      "v3" = 0,
                      "true_v" = 1)

effects_observed <- coef(mdl)[names(effects_expected)]

# the differences between observed and expected estimates is small
abs(effects_expected - effects_observed) |> 
  enframe(name = 'predictor',
          value = 'bias')

```

__Effect size estimation for non-linear effects__: This test verifies that, when the oracle model is used, the estimated effect sizes for variables with non-linear effects are consistent with the effect sizes used to simulate the data.

```{r}

data_gg <- 
  list(w1 = as.data.frame(Predict(mdl, w1)) |> select(x=w1, yhat),
       w2 = as.data.frame(Predict(mdl, w2)) |> select(x=w2, yhat),
       w3 = as.data.frame(Predict(mdl, w3)) |> select(x=w3, yhat)) |> 
  bind_rows(.id = 'xvar') |> 
  filter(x > -2.5, x < 2.5) |> 
  mutate(xvar = recode(xvar,
                       w1 = "Non-linear variable: w1",
                       w2 = "Non-linear variable: w2",
                       w3 = "Non-linear variable: w3")) |> 
  as_tibble()

# We expect increasing wiggle from left to right. 

ggplot(data_gg) + 
  aes(x = x, y = yhat) + 
  geom_line() + 
  facet_wrap(~ xvar) + 
  theme_bw() + 
  labs(x = 'W value', y = 'Estimated log-hazard')

```

These results verify that the simulated data set has the expected properties 
# Simulation Study

I compare four different techniques to measure variable importance (VI).  

1. `Negation importance`: the method I propose to develop further with this pilot application. This is computed using an oblique random survival forest model.

1. `ANOVA importance`: A method introduced by Menze et al. This is computed using an oblique random survival forest model.

1. `SHAP importance`: A method introduced by Lundberg et al. SHAP importance is widely regarded as a gold standard due to its excellent asymptotic properties. This is computed using a boosting model. 

1. `Permutation importance`: A method introduced by Leo Breiman. This is computed using a standard random survival forest model.

__Evaluation of variable importance techniques__: VI techniques are compared based on their discrimination (C-statistic) between relevant and irrelevant predictor variables. The relevant predictor variables are those that have a relationship to the outcome ($x$, $w$, $g$, and $v$ variables), and the irrelevant variables are those with no relationship to the outcome, i.e. the $z$ variables. This is equivalent to assigning a binary outcome to each variable: 1 if it is relevant, 0 otherwise, and then computing a C-statistic for discrimination of the relevant versus irrelevant variables using variable importance as a 'prediction' for the variables. 

__Details on C-statistic computation:__ The C-statistic is computed using `yardstick::roc_auc`, which wraps `pROC::roc`. To illustrate, if a variable importance metric assigned higher importance for all of the $x$ variables compared to all the $z$ variables, it would have a C-statistic of 1 for the $x$ variables.

## Results

Table 1: Discrimination between relevant and irrelevant predictor variables for each VI technique in 6 different simulated scenarios. Cells that are highlighted with a light blue color indicate which variable importance technique had the best discrimination for a given sample size, correlation setting, and variable type. For example, ANOVA importance had the best discrimination for linear effects with N = 2,500 and zero correlation between the linear effects and irrelevant variables. However, when the correlation between linear effects and irrelevant variables was non-zero, negation importance had the best discrimination across all scenarios and for each effect type. Given the low likelihood of ever having a real dataset with zero correlation between the predictor variables, these data suggest that negation importance can be very beneficial in applied settings. 

```{r}

data_gt <-  
  benchmark_vi_smry |>
  ungroup() |> 
  mutate(xcorr = recode(xcorr, 
                        '0.0' = '|Corr(linear effect variables, irrelevant variables)| = 0',
                        '0.1' = '|Corr(linear effect variables, irrelevant variables)| \u2264 0.10',
                        '0.2' = '|Corr(linear effect variables, irrelevant variables)| \u2264 0.20',
                        '0.3' = '|Corr(linear effect variables, irrelevant variables)| \u2264 0.30',
                        '0.4' = '|Corr(linear effect variables, irrelevant variables)| \u2264 0.40'),
         model = recode(model,
                        'aorsf' = 'Negation importance',
                        'aorsf_menze' = 'ANOVA importance',
                        'xgboost' = 'SHAP importance',
                        'randomForestSRC' = 'Permutation importance')) |> 
  select(n_obs, model, xcorr, overall, x, w, g, v, c) |> 
  pivot_wider(names_from = n_obs, 
              values_from = c(overall, x, w, g, v, c)) |> 
  select(xcorr,
         model,
         overall_2500,
         x_2500,
         w_2500,
         g_2500,
         v_2500,
         c_2500,
         overall_5000,
         x_5000,
         w_5000,
         g_5000,
         v_5000,
         c_5000) |> 
  arrange(xcorr, model)

cols_to_highlight <- c("overall_2500",
                       "x_2500",
                       "w_2500",
                       "g_2500",
                       "v_2500",
                       "c_2500",
                       "overall_5000",
                       "x_5000",
                       "w_5000",
                       "g_5000",
                       "v_5000",
                       "c_5000")

max_row_positions <- data_gt |>
  group_by(xcorr) |> 
  summarize(across(all_of(cols_to_highlight), which.max)) |> 
  mutate(xcorr = c(0, 4, 8, 12, 16)) |> 
  pivot_longer(cols = -xcorr) |> 
  mutate(value = value + xcorr) |> 
  select(name, value)

code_styles <- map2_chr(
  .x = max_row_positions$value,
  .y = max_row_positions$name,
  .f = ~ paste0(
    "|>",
    "tab_style(style = cell_fill(color = 'lightblue')",
    ", locations = cells_body(columns = ", .y, ",rows = ", .x, "))"
  )
)



results_tbl_1 <- data_gt |> 
  mutate(across(ends_with("0"), ~table_value(100*.x))) |> 
  gt(rowname_col = 'model', groupname_col = 'xcorr') |> 
  tab_stubhead(label = 'Variable importance technique') |> 
  tab_spanner(label = 'N = 2,500', 
              columns = c("overall_2500",
                          "x_2500",
                          "w_2500",
                          "g_2500",
                          "v_2500",
                          "c_2500")) |> 
  tab_spanner(label = 'N = 5,000', 
              columns = c("overall_5000",
                          "x_5000",
                          "w_5000",
                          "g_5000",
                          "v_5000",
                          "c_5000")) |> 
  cols_label(
    overall_2500 = "All effects",
    x_2500 = "Linear effects",
    w_2500 = "Non-linear effects",
    g_2500 = "Interaction effects",
    v_2500 = "Combo effects",
    c_2500 = "Categorical effects",
    overall_5000 = "All effects",
    x_5000 = "Linear effects",
    w_5000 = "Non-linear effects",
    g_5000 = "Interaction effects",
    v_5000 = "Combo effects",
    c_5000 = "Categorical effects"
  ) |> 
  cols_align(align = 'center')

code_to_run <- paste0('results_tbl_1', 
                      paste0(code_styles, collapse = ''))

eval(rlang::parse_expr(code_to_run))


```

### Overall summary

Due to space constraints, the pilot application presents a summary of the results in Table 1. This summary aggregates the results from the 6 scenarios presented above, and it is shown here here to verify.

```{r}

data_fig <- benchmark_vi_smry |>
  ungroup() |> 
  mutate(
    n_obs = recode(n_obs,
                   '2500' = 'Training data sample size = 2,500',
                   '5000' = 'Training data sample size = 5,000'),
    model = factor(model,
                   levels = c('aorsf',
                              'aorsf_menze',
                              'xgboost',
                              'randomForestSRC'),
                   labels = c('Negation importance',
                              'ANOVA importance',
                              'SHAP importance',
                              'Permutation importance'))
  )

fig <- ggplot(data_fig) + 
  aes(x = xcorr, y = overall, col = model) + 
  geom_line() +
  geom_point(size = 2) +
  scale_color_manual(values = c("purple", "orange", "grey", "limegreen")) +
  facet_wrap(~n_obs) + 
  labs(x = "max( |Corr(linear effect variables, irrelevant variables)| )",
       y = "Discrimination between relevant\nand irrelevant predictor variables",
       color = 'Variable importance\nestimated using') + 
  theme_bw() + 
  theme(panel.grid = element_blank())

ggsave(filename = 'plot_violet.png',
       plot = fig,
       device = 'png',
       width = 9,
       height = 4,
       dpi = 600)

fig

```

Table 2: Discrimination between relevant and irrelevant predictor variables for each VI technique. Negation importance obtains the highest C-statistic for each variable type except non-linear variables, where it closely trails SHAP importance.

```{r}

results_tbl_2 <- benchmark_vi_smry |>
  ungroup() |> 
  mutate(model = recode(model,
                        'aorsf' = 'Negation importance',
                        'aorsf_menze' = 'ANOVA importance',
                        'xgboost' = 'SHAP importance',
                        'randomForestSRC' = 'Permutation importance')) |> 
  select(n_obs, model, xcorr, overall, x, w, g, v, c) |> 
  group_by(model) |> 
  summarize(
    across(
      c(overall, x, w, g, v, c),
      ~table_value(mean(.x))
    )
  ) |> 
  gt(rowname_col = 'model') |> 
  tab_stubhead(label = 'Variable importance technique') |> 
  cols_label(
    overall = "Overall",
    x = "Linear effects",
    w = "Non-linear effects",
    g = "Interaction effects",
    v = "Combo effects",
    c = "Categorical effects"
  ) |> 
  cols_align(align = 'center')

results_tbl_2

```


# Conclusion

The strengths of negation importance are:

1. It can be computed for any type of oblique random forest, as it only leverages the linear coefficients in the nodes. (ANOVA importance requires a p-value be computed for each variable in each node).

1. It penalizes over-fitting by evaluating performance in out-of-bag data.

1. In the current simulation, it had the most reliable estimate of variable importance when irrelevant variables were correlated to relevant ones.


# REFERENCES

1. Source for `pbc_orsf` data: T Therneau and P Grambsch (2000), Modeling Survival Data: Extending the Cox Model, Springer-Verlag, New York. ISBN: 0-387-98784-3.

1. Source for `rotterdam` data: Patrick Royston and Douglas Altman, External validation of a Cox prognostic model: principles and methods. BMC Medical Research Methodology 2013, 13:33

